{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql import types as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Reddit Sentiment Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the Parquet file\n",
    "file_path = \"data/the-reddit-covid-comments-sample.parquet\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = spark.read.parquet(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"subreddit.id\", \"subreddit_id\")\n",
    "df = df.withColumnRenamed(\"subreddit.name\", \"subreddit_name\")\n",
    "df = df.withColumnRenamed(\"subreddit.nsfw\", \"subreddit_nsfw\")\n",
    "\n",
    "# Show the DataFrame schema and first few rows\n",
    "df.printSchema()  # Print the schema\n",
    "df.show(5)        # Display the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment score calculation - VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply VADER sentiment analysis\n",
    "def calculate_vader_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return float(scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register UDF to apply VADER sentiment\n",
    "vader_sentiment_udf = F.udf(calculate_vader_sentiment)\n",
    "\n",
    "# Apply VADER sentiment to each row and create a new column\n",
    "df = df.withColumn(\"vader_sentiment\", vader_sentiment_udf(F.col(\"body\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sentiment Per Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Average Sentiment per Subreddit\n",
    "avg_sentiment_per_subreddit = df.groupBy(\"subreddit_name\").agg(\n",
    "    F.avg(\"vader_sentiment\").alias(\"avg_sentiment\")\n",
    ")\n",
    "avg_sentiment_per_subreddit.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Similar Subreddits Based on Sentiment\n",
    "# Feature Engineering: Use average sentiment per subreddit as feature for clustering\n",
    "feature_df = avg_sentiment_per_subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the features for clustering\n",
    "assembler = VectorAssembler(inputCols=[\"avg_sentiment\"], outputCol=\"features\")\n",
    "feature_df = assembler.transform(avg_sentiment_per_subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a KMeans model and calculate cluster labels\n",
    "kmeans = KMeans(k=3, seed=1, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "model = kmeans.fit(feature_df)\n",
    "clustered_df = model.transform(feature_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Convert to dense numpy arrays if needed\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    # Avoid division by zero\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return float(0)\n",
    "    return float(dot_product / (norm_vec1 * norm_vec2))\n",
    "\n",
    "# Register the UDF with Spark\n",
    "cosine_similarity_udf = F.udf(cosine_similarity, T.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise cosine similarity of subreddits in each cluster\n",
    "similarity_df = clustered_df.alias(\"df1\").join(\n",
    "    clustered_df.alias(\"df2\"),\n",
    "    (F.col(\"df1.cluster\") == F.col(\"df2.cluster\")) & (F.col(\"df1.subreddit_name\") < F.col(\"df2.subreddit_name\"))\n",
    ").select(\n",
    "    F.col(\"df1.subreddit_name\").alias(\"subreddit_1\"),\n",
    "    F.col(\"df2.subreddit_name\").alias(\"subreddit_2\"),\n",
    "    cosine_similarity_udf(\"df1.features\", \"df2.features\").alias(\"similarity_score\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "similarity_df.show(5)\n",
    "\n",
    "similarity_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correlation Between VADER Sentiment and Reddit Score\n",
    "# Ensure both columns are numeric by casting to double\n",
    "sentiment_score_relation = df.select(\n",
    "    F.col(\"vader_sentiment\").cast(\"double\").alias(\"vader_sentiment\"),\n",
    "    F.col(\"score\").cast(\"double\").alias(\"score\")\n",
    ")\n",
    "\n",
    "# Calculate the correlation between the two columns\n",
    "correlation = sentiment_score_relation.corr(\"vader_sentiment\", \"score\")\n",
    "print(f\"Correlation between VADER sentiment and Reddit score: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrames to Pandas for visualization\n",
    "avg_sentiment_df = avg_sentiment_per_subreddit.toPandas()\n",
    "similarity_df_pd = similarity_df.toPandas()\n",
    "sentiment_score_relation_pd = sentiment_score_relation.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Visualization 1: Average Sentiment per Subreddit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"avg_sentiment\", y=\"subreddit_name\", data=avg_sentiment_df.sort_values(\"avg_sentiment\", ascending=False))\n",
    "plt.title(\"Average Sentiment per Subreddit\")\n",
    "plt.xlabel(\"Average Sentiment\")\n",
    "plt.ylabel(\"Subreddit Name\")\n",
    "plt.axvline(0, color='red', linestyle='--')  # Line at sentiment 0 for reference\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Similar Subreddits Based on Sentiment\n",
    "# Pivot for heatmap\n",
    "similarity_matrix = similarity_df_pd.pivot(\"subreddit_1\", \"subreddit_2\", \"similarity_score\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix, cmap=\"coolwarm\", annot=True, fmt=\".2f\", cbar_kws={'label': 'Similarity Score'})\n",
    "plt.title(\"Cosine Similarity Between Subreddits Based on Sentiment\")\n",
    "plt.xlabel(\"Subreddit 2\")\n",
    "plt.ylabel(\"Subreddit 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Correlation Between Sentiment and Reddit Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=sentiment_score_relation_pd, x=\"vader_sentiment\", y=\"score\")\n",
    "plt.title(\"Correlation Between VADER Sentiment and Reddit Score\")\n",
    "plt.xlabel(\"VADER Sentiment Score\")\n",
    "plt.ylabel(\"Reddit Score\")\n",
    "plt.axhline(0, color='red', linestyle='--')  # Line at score 0 for reference\n",
    "plt.axvline(0, color='red', linestyle='--')  # Line at sentiment 0 for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the correlation line\n",
    "sns.regplot(data=sentiment_score_relation_pd, x=\"vader_sentiment\", y=\"score\", scatter=False, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
